---
title: 'AI as a tool for direction'
publishedAt: '2025-03-15'
summary: 'It is what it is'
---

Wait wait, before you start bringing out the pitchforks, hear me out.

Now, using solely AI to generate code and do everything for you, I'm pretty sure most of us can agree that it doesn't do us much good in the long run.

Sure, you might get a working product in a pretty short amount of time, but chances are that you won't fully understand what it's doing, which will inevitably come back to bite you later on.

However, pretending that AI isn't here to stay isn't realistic either. Generative AI has already irreversibly changed how we code, how we think and even how we learn.

It's nearly impossible to go back, and by not utilizing it, you're putting yourself at a huge disadvantage, even with all of the pitfalls that come from relying on AI.

My point is, Generative AI LLMs like ChatGPT, DeepSeek, Claude, etc. are just a tool, an immensely useful one if you know how to use it right.

## Let's talk about Copilot
I'd argue that Copilot is easily one of the worst AI tools to add to your repertoire, it's far too convenient, and relying too heavily on it can cause you to frequently short-circuit your own thinking process.

Copilot's auto-fill is poison to the mind of the developer, a simple example is forgetting how to write basic syntax, like a for loop, just because you're so used to having Copilot do it for you.

In my opinion, Copilot is best used as a refactoring tool, its ability to read your source code from the IDE makes it extremely good at tasks like extracting hard-coded constants into variables, just make sure you double check the generated code.

## Claude, DeepSeek, etc.
As of the time of writing, Claude (3.7 Sonnet) is arguably the best "AI Assistant" for developing software and writing code in general.  It's almost tailor-made for software development, and can frequently output convincing results that work on the first try.

However, all coding "AI Assistants" suffer from similar pitfalls, whereby the deeper you dive into a topic, the more incoherent the AI seems to become. The AI starts to hallucinate solutions, start making things up, and just being confusing overall.

Never take an LLM's output at face value, as more often than not, it's going to try to lie to you. The best way to use these tools is as a quick lookup, a cursory glance into a topic to establish a direction to work towards.

## Effective use of LLMs as a search tool
Start with the topic, idea or question that you want to know about, then ask at least two LLMs using the same prompt. Cross-reference their output to make sure that they aren't just hallucinating nonsense. Statistically, if both LLMs generate similar output, the contents are likely to be found somewhere on the internet.

With this in mind, start narrowing down the scope of your question by first using regular search engine queries, reading and thinking about articles and discussions by skilled people is likely to be far more effective at improving your understanding of the topic than just accepting what the chatbot tells you.

## Speed vs. Effectiveness
If your goal isn't to understand a topic, but to get a working product out as soon as possible, then by all means, go wild with Generative AI. In fact, the tendency of LLMs to hallucinate can actually generate some very interesting ideas.

WIP