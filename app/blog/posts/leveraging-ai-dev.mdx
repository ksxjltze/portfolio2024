---
title: 'AI as a tool for direction'
publishedAt: '2025-03-15'
updatedAt: '2025-03-27'
summary: 'It is what it is'
---

Wait wait, before you start bringing out the pitchforks, hear me out.

Now, using solely AI to generate code and do everything for you, I'm pretty sure most of us can agree that it doesn't do us much good in the long run.

Sure, you might get a working product in a pretty short amount of time, but chances are that you won't fully understand what it's doing, which will inevitably come back to bite you later on.

However, pretending that AI isn't here to stay isn't realistic either. Generative AI has already irreversibly changed how we code, how we think and even how we learn.

## A new era

It's nearly impossible to go back to the days before AI assistants, and by not utilizing it, you're putting yourself at a huge disadvantage, even with all of the pitfalls that come from relying on AI.

My point is, Generative AI Agents/Assistants/LLMs like ChatGPT, DeepSeek, Manus, Claude, etc. are just tools, immensely useful ones if you know how to use them right.

## Let's talk about Copilot
I'd argue that Copilot is easily one of the worst AI tools to add to your repertoire, it's far too convenient, and relying too heavily on it can cause you to frequently short-circuit your own thinking process.

Copilot's auto-fill is poison to the mind of the developer, a simple example is forgetting how to write basic syntax, like a for loop, just because you're so used to having Copilot do it for you.

In my opinion, Copilot is best used as a refactoring tool, its ability to read your source code from the IDE makes it extremely good at tasks like extracting hard-coded constants into variables, just make sure you double check the generated code.

## AI Assisted Development, etc.
As of the time of writing, Claude (3.7 Sonnet) is arguably the best "AI Assistant" for developing software and writing code in general.  It's almost tailor-made for software development, and can frequently output convincing results that work on the first try.

However, all coding "AI Assistants" suffer from similar pitfalls, whereby the deeper you dive into a topic, the more incoherent the AI seems to become. The AI starts to hallucinate solutions, start making things up, and just being confusing overall.

Never take an LLM's output at face value, as more often than not, it's going to try to lie to you. The best way to use these tools is as a quick lookup, a cursory glance into a topic to establish a direction to work towards.

## Effective use of LLMs as a search tool
Start with the topic, idea or question that you want to know about, then ask at least two LLMs using the same prompt. Cross-reference their output to make sure that they aren't just hallucinating nonsense. Statistically, if both LLMs generate similar output, the contents are likely to be found somewhere on the internet.

With this in mind, start narrowing down the scope of your question by first using regular search engine queries, reading and thinking about articles and discussions by skilled people is likely to be far more effective at improving your understanding of the topic than just accepting what the chatbot tells you.

## Practicality
If your goal isn't to understand a topic, but to get a working product out as soon as possible, then by all means, go wild with Generative AI. 

In fact, the tendency of LLMs to hallucinate can actually generate some very interesting ideas.
Using AI effectively is all about knowing how to achieve the best balance between speed, understanding, code complexity.

At the end of the day, AI is just another tool. A true master does not blame their tools, but knows how to make the best use of them.

## Autonomous AI Coding Agents
Recently, "Vibe Coding" has been all the hype, getting praise and vitriol thrown at it from both sides of the pond.

Skeptical I may be, but I've decided to keep my mind open and dip my toes into the water.

I tried two coding agents, Cline and Aider, I generally didn't see any point in using either of them, for my use cases anyway.

## What I liked
1.  Cline's memory bank feature is interesting, providing a great deal of context for LLMs to work with about your project. 

    In fact, I believe its a pretty neat way to generate basic documentation about your project, simply by initializing the memory bank.

2. The AI agent can actually commit its changes to git for you, so at least you don't have to worry about it accidentally nuking your entire code base.

3. It's pretty good at generating boilerplate code.

## What I didn't like
1. It's kinda expensive if you want actual results. At the moment, only Claude 3.7 Sonnet can really output anything useful without you basically hand-holding/micro-managing the LLM. 

    Unfortunately, it costs quite a bit, I burnt through my free credits in about 10 minutes; no more fun, much sadge.

    Free options do exist, like using DeepSeek-R1 (Free) through OpenRouter, or even hosting your own LLM locally using ollama, but none of these can hold a candle to Claude.

2. Aider just felt meh, use Cline instead.

## My conclusion about "Vibe Coding"
It's not for me. Perhaps it would be suitable if I were more inclined to be an extremely detailed oriented project manager, but it's simply too much hassle right now to get it to do what I actually want.

At best, in its current state, it's great for generating boilerplate for common project patterns, but anything deeper will require far more effort in both prompting and project management.

I think it's a decent entry point into software development for those without a technical background, especially since it's highly likely to expose your to common programming patterns, but if you already know how to code, you're better off just doing it yourself and skipping the "middle man".

Although, at the rate that AI seems to be progressing, if costs become neglible while maintaining growth in capabilities and reasoning, these tools may yet become actually excellent assistants for even seasoned programmers.